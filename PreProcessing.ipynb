{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types, Row, Column\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"finalProject\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in raw text set and write to parquet\n",
    "# train = spark.read.option('header', 'false').csv('data/train.txt', sep='\\t')\n",
    "# train.write.format('parquet').save('data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in parqet\n",
    "train = spark.read.parquet('data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'n0',\n",
       " 'n1',\n",
       " 'n2',\n",
       " 'n3',\n",
       " 'n4',\n",
       " 'n5',\n",
       " 'n6',\n",
       " 'n7',\n",
       " 'n8',\n",
       " 'n9',\n",
       " 'n10',\n",
       " 'n11',\n",
       " 'n12',\n",
       " 'c0',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'c3',\n",
       " 'c4',\n",
       " 'c5',\n",
       " 'c6',\n",
       " 'c7',\n",
       " 'c8',\n",
       " 'c9',\n",
       " 'c10',\n",
       " 'c11',\n",
       " 'c12',\n",
       " 'c13',\n",
       " 'c14',\n",
       " 'c15',\n",
       " 'c16',\n",
       " 'c17',\n",
       " 'c18',\n",
       " 'c19',\n",
       " 'c20',\n",
       " 'c21',\n",
       " 'c22',\n",
       " 'c23',\n",
       " 'c24',\n",
       " 'c25']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename label column\n",
    "train = train.withColumnRenamed('_c0', 'label')\n",
    "\n",
    "# remove underscores\n",
    "for c in train.columns[1:]:\n",
    "    train = train.withColumnRenamed(c, c.strip('_'))\n",
    "\n",
    "for i,c in enumerate(train.columns[1:14]):\n",
    "    newName = 'n' + str(i)\n",
    "    train = train.withColumnRenamed(c, newName)\n",
    "    \n",
    "for i,c in enumerate(train.columns[14:]):\n",
    "    newName = 'c' + str(i)\n",
    "    train = train.withColumnRenamed(c, newName)\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: float (nullable = true)\n",
      " |-- n0: float (nullable = true)\n",
      " |-- n1: float (nullable = true)\n",
      " |-- n2: float (nullable = true)\n",
      " |-- n3: float (nullable = true)\n",
      " |-- n4: float (nullable = true)\n",
      " |-- n5: float (nullable = true)\n",
      " |-- n6: float (nullable = true)\n",
      " |-- n7: float (nullable = true)\n",
      " |-- n8: float (nullable = true)\n",
      " |-- n9: float (nullable = true)\n",
      " |-- n10: float (nullable = true)\n",
      " |-- n11: float (nullable = true)\n",
      " |-- n12: float (nullable = true)\n",
      " |-- c0: string (nullable = true)\n",
      " |-- c1: string (nullable = true)\n",
      " |-- c2: string (nullable = true)\n",
      " |-- c3: string (nullable = true)\n",
      " |-- c4: string (nullable = true)\n",
      " |-- c5: string (nullable = true)\n",
      " |-- c6: string (nullable = true)\n",
      " |-- c7: string (nullable = true)\n",
      " |-- c8: string (nullable = true)\n",
      " |-- c9: string (nullable = true)\n",
      " |-- c10: string (nullable = true)\n",
      " |-- c11: string (nullable = true)\n",
      " |-- c12: string (nullable = true)\n",
      " |-- c13: string (nullable = true)\n",
      " |-- c14: string (nullable = true)\n",
      " |-- c15: string (nullable = true)\n",
      " |-- c16: string (nullable = true)\n",
      " |-- c17: string (nullable = true)\n",
      " |-- c18: string (nullable = true)\n",
      " |-- c19: string (nullable = true)\n",
      " |-- c20: string (nullable = true)\n",
      " |-- c21: string (nullable = true)\n",
      " |-- c22: string (nullable = true)\n",
      " |-- c23: string (nullable = true)\n",
      " |-- c24: string (nullable = true)\n",
      " |-- c25: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cast numerical is float\n",
    "for c in train.columns[:14]:\n",
    "    train = train.withColumn(c, train[c].cast('float'))\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45601"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a sample\n",
    "s = train.sample(False, 0.001)\n",
    "s.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=1.0, n0=None, n1=20.0, n2=70.0, n3=26.0, n4=4.0, n5=None, n6=0.0, n7=25.0, n8=26.0, n9=None, n10=0.0, n11=None, n12=26.0, c0='68fd1e64', c1='b80912da', c2='45d73e26', c3='4e2622db', c4='4cf72387', c5='7e0ccccf', c6='635cdf1c', c7='5b392875', c8='a73ee510', c9='3b08e48b', c10='099f88a2', c11='59df9ec7', c12='5bc02dfd', c13='07d13a8f', c14='569913cf', c15='6cd2843a', c16='776ce399', c17='7119e567', c18='19050a44', c19='a458ea53', c20='a6d51873', c21=None, c22='3a171ecb', c23='0dfdc7d2', c24='e8b83407', c25='def102a7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample, testSample = s.randomSplit([1.0, 9.0], 666)\n",
    "trainSample = trainSample.cache()\n",
    "testSample = testSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4652, 40949)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.count(), testSample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 ms, sys: 30 ms, total: 60 ms\n",
      "Wall time: 4.85 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# stats = trainSample[trainSample.columns[1:14]].describe()\n",
    "# maxes = np.array(stats[stats['summary'] == 'max'].collect())[0][1:]\n",
    "# mins = np.array(stats[stats['summary'] == 'min'].collect())[0][1:]\n",
    "# maxes = [float(m) for m in maxes]\n",
    "# mins = [float(m) for m in mins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize columns\n",
    "# for i,c in enumerate(trainSample.columns[1:14]):\n",
    "#     trainSample = trainSample.withColumn(c, (trainSample[c] - mins[i]) / (maxes[i] - mins[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(n0=None, n1=0.0, n2=0.00047080979284369113, n3=0.012658227848101266, n4=0.0045070462648655095, n5=0.01849537615596101, n6=0.0014814814814814814, n7=0.03768844221105527, n8=0.014874371859296482, n9=None, n10=0.022727272727272728, n11=None, n12=0.005154639175257732)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainSample.select(trainSample.columns[1:14]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need to decide on proper NA handling later on, for now filling with 0\n",
    "# trainSample = trainSample.na.fill(0, subset=trainSample.columns[1:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(n0=0.0, n1=0.0, n2=0.00047080979284369113, n3=0.012658227848101266, n4=0.0045070462648655095, n5=0.01849537615596101, n6=0.0014814814814814814, n7=0.03768844221105527, n8=0.014874371859296482, n9=0.0, n10=0.022727272727272728, n11=0.0, n12=0.005154639175257732)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainSample.select(trainSample.columns[1:14]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeNumeric(trainDf, testDf):\n",
    "    stats = trainDf[trainDf.columns[1:14]].describe()\n",
    "    maxes = np.array(stats[stats['summary'] == 'max'].collect())[0][1:]\n",
    "    mins = np.array(stats[stats['summary'] == 'min'].collect())[0][1:]\n",
    "    maxes = [float(m) for m in maxes]\n",
    "    mins = [float(m) for m in mins]\n",
    "    \n",
    "    for i,c in enumerate(trainDf.columns[1:14]):\n",
    "        trainDf = trainDf.withColumn(c, (trainDf[c] - mins[i]) / (maxes[i] - mins[i]))\n",
    "        testDf = testDf.withColumn(c, (testDf[c] - mins[i]) / (maxes[i] - mins[i]))\n",
    "        \n",
    "    # NEED TO FIGURE THIS OUT FIRST\n",
    "    trainDf = trainDf.na.fill(0, subset=trainDf.columns[1:14])\n",
    "    testDf = testDf.na.fill(0, subset=testDf.columns[1:14])\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample, testSample = normalizeNumeric(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.00016105653084232566, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='5bfa8ab5', c1='e6203a55', c2='a406a722', c3='f0249dbe', c4='25c83c98', c5='6f6d9be8', c6='3d4f5cb7', c7='0b153874', c8='7cc72ec2', c9='3b08e48b', c10='53be0d4b', c11='3e76d3fa', c12='8803181f', c13='07d13a8f', c14='c7cb28b6', c15='d089fb6d', c16='2005abd1', c17='2e39068c', c18=None, c19=None, c20='4095765f', c21=None, c22='32c7478e', c23='5414e525', c24=None, c25=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.00016105653084232566, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='68fd1e64', c1='61e10608', c2='fae1bc10', c3='28d926b8', c4='25c83c98', c5='fe6b92e5', c6='b5b7ad43', c7='0b153874', c8='7cc72ec2', c9='3b08e48b', c10='364bff6f', c11='9576d76f', c12='31d2ac00', c13='07d13a8f', c14='b431bed8', c15='fc53f85c', c16='2005abd1', c17='a6af02f7', c18=None, c19=None, c20='ed35ed93', c21=None, c22='be7c41b4', c23='4fcc135f', c24=None, c25=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = trainSample.select(trainSample.columns[14:]).summary('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = trainSample.groupBy('c0').count()\n",
    "# c.collect()[0]\n",
    "# # type(c)\n",
    "# # c = c.orderBy(c.count.desc()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findInfrequentValues(c, n=10):\n",
    "#     # c is the column that we are operating on\n",
    "#     # \n",
    "#     counts = trainSample.groupBy(c).count()\n",
    "#     infrequentValues = counts.filter(counts['count'] <= n)\n",
    "#     s = infrequentValues.agg(F.collect_set(c)).collect()[0][0]\n",
    "#     return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = replaceInfrequentValues('c0')\n",
    "# type(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = trainSample.withColumn('c0', F.when(trainSample['c0'] == names[0], '999').otherwise(trainSample['c0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(df['c0'] == names[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int('0x' + names[0], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert hex values to integers and modulo them\n",
    "# def hashValues(row):\n",
    "#     if row != None:\n",
    "#         return str(int('0x' + row, 16) % 10000)\n",
    "#     else:\n",
    "#         return str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf_object = F.udf(hashValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select('c0').collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.withColumn('c0', udf_object(trainSample['c0'])).select('c0').collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in trainSample.columns[14:]:\n",
    "#     trainSample = trainSample.withColumn(c, udf_object(trainSample[c]))\n",
    "#     testSample = testSample.withColumn(c, udf_object(testSample[c]))\n",
    "\n",
    "    \n",
    "# # trainSample = trainSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for c in trainSample.columns[14:]:\n",
    "#     newCol = c + '_idx'\n",
    "#     indexer = StringIndexer(inputCol=c, outputCol=newCol, handleInvalid='keep')\n",
    "# #     trainSample = indexer.fit(trainSample).transform(trainSample)\n",
    "#     sIdx = indexer.fit(trainSample)\n",
    "#     trainSample = sIdx.transform(trainSample)\n",
    "#     testSample = sIdx.transform(testSample)\n",
    "# trainSample = trainSample.cache()\n",
    "# testSample = testSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select(trainSample.columns[40:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.select(testSample.columns[40:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = trainSample.columns[40:]\n",
    "# outputCols = [c.strip('_idx') + '_OHE' for c in cols]\n",
    "# encoder = OneHotEncoderEstimator(inputCols=cols, outputCols=outputCols)\n",
    "# OHE = encoder.fit(trainSample)\n",
    "# trainSample = OHE.transform(trainSample)\n",
    "# testSample = OHE.transform(testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select(trainSample.columns[-26:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.select(testSample.columns[-26:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [c for c in trainSample.columns if 'n' in c or 'OHE' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "# trainSample = v.transform(trainSample)\n",
    "# testSample = v.transform(testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.columns[-1], testSample.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatureVector(trainDf, testDf):\n",
    "    # create hash function for binning categorical variables\n",
    "    def hashValues(row):\n",
    "        if row != None:\n",
    "            # return integer value of hex label, modulo by 10000 (keep only the last 4 digits)\n",
    "            return str(int('0x' + row, 16) % 10000)\n",
    "        else:\n",
    "            return str(row)\n",
    "    \n",
    "    # create the udf object from the helper function\n",
    "    udf_object = F.udf(hashValues)\n",
    "    \n",
    "    # hash all hex strings in both train and test\n",
    "    for c in trainDf.columns[14:]:\n",
    "        trainDf = trainDf.withColumn(c, udf_object(trainDf[c]))\n",
    "        testDf = testDf.withColumn(c, udf_object(testDf[c]))\n",
    "        \n",
    "    # index the hash values into categories\n",
    "    for c in trainDf.columns[14:]:\n",
    "        newCol = c + '_idx'\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=newCol, handleInvalid='keep')\n",
    "        f = indexer.fit(trainDf)\n",
    "        trainDf = f.transform(trainDf)\n",
    "        testDf = f.transform(testDf)\n",
    "        \n",
    "    # One-hot encode the categorical indices\n",
    "    inputCols = trainDf.columns[40:]\n",
    "    outputCols = [c.strip('_idx') + '_OHE' for c in inputCols]\n",
    "    encoder = OneHotEncoderEstimator(inputCols=inputCols, outputCols=outputCols)\n",
    "    e = encoder.fit(trainDf)\n",
    "    trainDf = e.transform(trainDf)\n",
    "    testDf = e.transform(testDf)\n",
    "    \n",
    "    # assemble all features into single SparseVector column\n",
    "    cols = [c for c in trainDf.columns if 'n' in c or 'OHE' in c]\n",
    "    v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "    trainDf = v.transform(trainDf)\n",
    "    testDf = v.transform(testDf)\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample, testSample = createFeatureVector(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('features', 'features')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.columns[-1], testSample.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(23784, {1: 0.0002, 13: 1.0, 405: 1.0, 1948: 1.0, 2246: 1.0, 3931: 1.0, 4658: 1.0, 7032: 1.0, 7041: 1.0, 7111: 1.0, 8308: 1.0, 9412: 1.0, 10938: 1.0, 11740: 1.0, 12113: 1.0, 14356: 1.0, 14358: 1.0, 14372: 1.0, 14539: 1.0, 15176: 1.0, 17548: 1.0, 18032: 1.0, 18383: 1.0, 19675: 1.0, 19910: 1.0, 21666: 1.0, 22429: 1.0}))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(23784, {1: 0.0002, 13: 1.0, 910: 1.0, 1948: 1.0, 2474: 1.0, 3826: 1.0, 4658: 1.0, 4695: 1.0, 7041: 1.0, 7381: 1.0, 8308: 1.0, 9409: 1.0, 9451: 1.0, 11740: 1.0, 12159: 1.0, 14356: 1.0, 14363: 1.0, 14372: 1.0, 14557: 1.0, 15278: 1.0, 17652: 1.0, 18032: 1.0, 18379: 1.0, 18514: 1.0, 19910: 1.0, 21666: 1.0, 21764: 1.0}))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample.write.format('parquet').save('data/trainSample.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
