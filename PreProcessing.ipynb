{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types, Row, Column\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"finalProject\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in raw text set and write to parquet\n",
    "# train = spark.read.option('header', 'false').csv('data/train.txt', sep='\\t')\n",
    "# train.write.format('parquet').save('data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in parqet\n",
    "train = spark.read.parquet('data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'n0',\n",
       " 'n1',\n",
       " 'n2',\n",
       " 'n3',\n",
       " 'n4',\n",
       " 'n5',\n",
       " 'n6',\n",
       " 'n7',\n",
       " 'n8',\n",
       " 'n9',\n",
       " 'n10',\n",
       " 'n11',\n",
       " 'n12',\n",
       " 'c0',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'c3',\n",
       " 'c4',\n",
       " 'c5',\n",
       " 'c6',\n",
       " 'c7',\n",
       " 'c8',\n",
       " 'c9',\n",
       " 'c10',\n",
       " 'c11',\n",
       " 'c12',\n",
       " 'c13',\n",
       " 'c14',\n",
       " 'c15',\n",
       " 'c16',\n",
       " 'c17',\n",
       " 'c18',\n",
       " 'c19',\n",
       " 'c20',\n",
       " 'c21',\n",
       " 'c22',\n",
       " 'c23',\n",
       " 'c24',\n",
       " 'c25']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename label column\n",
    "train = train.withColumnRenamed('_c0', 'label')\n",
    "\n",
    "# remove underscores\n",
    "for c in train.columns[1:]:\n",
    "    train = train.withColumnRenamed(c, c.strip('_'))\n",
    "\n",
    "for i,c in enumerate(train.columns[1:14]):\n",
    "    newName = 'n' + str(i)\n",
    "    train = train.withColumnRenamed(c, newName)\n",
    "    \n",
    "for i,c in enumerate(train.columns[14:]):\n",
    "    newName = 'c' + str(i)\n",
    "    train = train.withColumnRenamed(c, newName)\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: float (nullable = true)\n",
      " |-- n0: float (nullable = true)\n",
      " |-- n1: float (nullable = true)\n",
      " |-- n2: float (nullable = true)\n",
      " |-- n3: float (nullable = true)\n",
      " |-- n4: float (nullable = true)\n",
      " |-- n5: float (nullable = true)\n",
      " |-- n6: float (nullable = true)\n",
      " |-- n7: float (nullable = true)\n",
      " |-- n8: float (nullable = true)\n",
      " |-- n9: float (nullable = true)\n",
      " |-- n10: float (nullable = true)\n",
      " |-- n11: float (nullable = true)\n",
      " |-- n12: float (nullable = true)\n",
      " |-- c0: string (nullable = true)\n",
      " |-- c1: string (nullable = true)\n",
      " |-- c2: string (nullable = true)\n",
      " |-- c3: string (nullable = true)\n",
      " |-- c4: string (nullable = true)\n",
      " |-- c5: string (nullable = true)\n",
      " |-- c6: string (nullable = true)\n",
      " |-- c7: string (nullable = true)\n",
      " |-- c8: string (nullable = true)\n",
      " |-- c9: string (nullable = true)\n",
      " |-- c10: string (nullable = true)\n",
      " |-- c11: string (nullable = true)\n",
      " |-- c12: string (nullable = true)\n",
      " |-- c13: string (nullable = true)\n",
      " |-- c14: string (nullable = true)\n",
      " |-- c15: string (nullable = true)\n",
      " |-- c16: string (nullable = true)\n",
      " |-- c17: string (nullable = true)\n",
      " |-- c18: string (nullable = true)\n",
      " |-- c19: string (nullable = true)\n",
      " |-- c20: string (nullable = true)\n",
      " |-- c21: string (nullable = true)\n",
      " |-- c22: string (nullable = true)\n",
      " |-- c23: string (nullable = true)\n",
      " |-- c24: string (nullable = true)\n",
      " |-- c25: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cast numerical is float\n",
    "for c in train.columns[:14]:\n",
    "    train = train.withColumn(c, train[c].cast('float'))\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a sample\n",
    "s = train.sample(False, 0.001)\n",
    "s.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=1.0, n1=11.0, n2=3.0, n3=3.0, n4=201.0, n5=3.0, n6=1.0, n7=3.0, n8=3.0, n9=1.0, n10=1.0, n11=None, n12=3.0, c0='05db9164', c1='207b2d81', c2='d9e96c5e', c3='0fa0d423', c4='25c83c98', c5='fbad5c96', c6='9c8ed289', c7='0b153874', c8='a73ee510', c9='dc650390', c10='a7b606c4', c11='8c51950e', c12='eae197fd', c13='cfef1c29', c14='f2237c1b', c15='6bb29970', c16='d4bb7bd8', c17='99cb5912', c18='21ddcdc9', c19='b1252a9d', c20='8f18d8d5', c21=None, c22='3a171ecb', c23='8fc66e78', c24='001f3601', c25='f37f3967')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sample\n",
    "trainSample, testSample = s.randomSplit([1.0, 9.0], 666)\n",
    "trainSample = trainSample.cache()\n",
    "testSample = testSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4639, 40805)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.count(), testSample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on full\n",
    "train, test = train.randomSplit([1.0, 9.0], 666)\n",
    "train = train.cache()\n",
    "test = test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.count(), test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# stats = trainSample[trainSample.columns[1:14]].describe()\n",
    "# maxes = np.array(stats[stats['summary'] == 'max'].collect())[0][1:]\n",
    "# mins = np.array(stats[stats['summary'] == 'min'].collect())[0][1:]\n",
    "# maxes = [float(m) for m in maxes]\n",
    "# mins = [float(m) for m in mins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize columns\n",
    "# for i,c in enumerate(trainSample.columns[1:14]):\n",
    "#     trainSample = trainSample.withColumn(c, (trainSample[c] - mins[i]) / (maxes[i] - mins[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select(trainSample.columns[1:14]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # need to decide on proper NA handling later on, for now filling with 0\n",
    "# trainSample = trainSample.na.fill(0, subset=trainSample.columns[1:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select(trainSample.columns[1:14]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeNumeric(trainDf, testDf):\n",
    "    stats = trainDf[trainDf.columns[1:14]].describe()\n",
    "    maxes = np.array(stats[stats['summary'] == 'max'].collect())[0][1:]\n",
    "    mins = np.array(stats[stats['summary'] == 'min'].collect())[0][1:]\n",
    "    maxes = [float(m) for m in maxes]\n",
    "    mins = [float(m) for m in mins]\n",
    "    \n",
    "    for i,c in enumerate(trainDf.columns[1:14]):\n",
    "        trainDf = trainDf.withColumn(c, (trainDf[c] - mins[i]) / (maxes[i] - mins[i]))\n",
    "        testDf = testDf.withColumn(c, (testDf[c] - mins[i]) / (maxes[i] - mins[i]))\n",
    "        \n",
    "    # NEED TO FIGURE THIS OUT FIRST\n",
    "    trainDf = trainDf.na.fill(0, subset=trainDf.columns[1:14])\n",
    "    testDf = testDf.na.fill(0, subset=testDf.columns[1:14])\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sample\n",
    "trainSample, testSample = normalizeNumeric(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0001520912547528517, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='05db9164', c1='38a947a1', c2='0e4f7fa4', c3='5deac079', c4='25c83c98', c5='7e0ccccf', c6='bca35340', c7='0b153874', c8='a73ee510', c9='3b08e48b', c10='bbf9c1a0', c11='1f6b8745', c12='a3fda569', c13='07d13a8f', c14='6c3ae388', c15='50d2b997', c16='2005abd1', c17='a2157fe3', c18=None, c19=None, c20='9c03188d', c21=None, c22='be7c41b4', c23='4b871c6a', c24=None, c25=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0001520912547528517, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='75ac2fe6', c1='38a947a1', c2=None, c3=None, c4='25c83c98', c5='7e0ccccf', c6='ba5d463e', c7='0b153874', c8='7cc72ec2', c9='3b08e48b', c10='2db82d51', c11=None, c12='6d41cadf', c13='b28479f6', c14='992454dc', c15=None, c16='2005abd1', c17='9b82aca5', c18=None, c19=None, c20=None, c21='ad3062eb', c22='32c7478e', c23=None, c24=None, c25=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 140 ms, total: 300 ms\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, test = normalizeNumeric(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=3.880812486902258e-06, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='05db9164', c1='31eb7ac1', c2='2dc2b523', c3='137a5e26', c4='25c83c98', c5='fe6b92e5', c6='ce8217f8', c7='5b392875', c8='7cc72ec2', c9='3b08e48b', c10='9d12ce9b', c11='d9510218', c12='9dfda2b9', c13='07d13a8f', c14='6cb56b0f', c15='57ddd4e0', c16='2005abd1', c17='e3f6ec41', c18=None, c19=None, c20='45458c05', c21=None, c22='be7c41b4', c23='1793a828', c24=None, c25=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = trainSample.select(trainSample.columns[14:]).summary('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = trainSample.groupBy('c0').count()\n",
    "# c.collect()[0]\n",
    "# # type(c)\n",
    "# # c = c.orderBy(c.count.desc()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findInfrequentValues(c, n=10):\n",
    "#     # c is the column that we are operating on\n",
    "#     # \n",
    "#     counts = trainSample.groupBy(c).count()\n",
    "#     infrequentValues = counts.filter(counts['count'] <= n)\n",
    "#     s = infrequentValues.agg(F.collect_set(c)).collect()[0][0]\n",
    "#     return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = replaceInfrequentValues('c0')\n",
    "# type(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = trainSample.withColumn('c0', F.when(trainSample['c0'] == names[0], '999').otherwise(trainSample['c0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(df['c0'] == names[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int('0x' + names[0], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert hex values to integers and modulo them\n",
    "# def hashValues(row):\n",
    "#     if row != None:\n",
    "#         return str(int('0x' + row, 16) % 10000)\n",
    "#     else:\n",
    "#         return str(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf_object = F.udf(hashValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select('c0').collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.withColumn('c0', udf_object(trainSample['c0'])).select('c0').collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in trainSample.columns[14:]:\n",
    "#     trainSample = trainSample.withColumn(c, udf_object(trainSample[c]))\n",
    "#     testSample = testSample.withColumn(c, udf_object(testSample[c]))\n",
    "\n",
    "    \n",
    "# # trainSample = trainSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for c in trainSample.columns[14:]:\n",
    "#     newCol = c + '_idx'\n",
    "#     indexer = StringIndexer(inputCol=c, outputCol=newCol, handleInvalid='keep')\n",
    "# #     trainSample = indexer.fit(trainSample).transform(trainSample)\n",
    "#     sIdx = indexer.fit(trainSample)\n",
    "#     trainSample = sIdx.transform(trainSample)\n",
    "#     testSample = sIdx.transform(testSample)\n",
    "# trainSample = trainSample.cache()\n",
    "# testSample = testSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select(trainSample.columns[40:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.select(testSample.columns[40:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = trainSample.columns[40:]\n",
    "# outputCols = [c.strip('_idx') + '_OHE' for c in cols]\n",
    "# encoder = OneHotEncoderEstimator(inputCols=cols, outputCols=outputCols)\n",
    "# OHE = encoder.fit(trainSample)\n",
    "# trainSample = OHE.transform(trainSample)\n",
    "# testSample = OHE.transform(testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select(trainSample.columns[-26:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.select(testSample.columns[-26:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [c for c in trainSample.columns if 'n' in c or 'OHE' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "# trainSample = v.transform(trainSample)\n",
    "# testSample = v.transform(testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.columns[-1], testSample.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatureVector(trainDf, testDf):\n",
    "    # create hash function for binning categorical variables\n",
    "    def hashValues(row):\n",
    "        if row != None:\n",
    "            # return integer value of hex label, modulo by 10000 (keep only the last 4 digits)\n",
    "            return str(int('0x' + row, 16) % 10000)\n",
    "        else:\n",
    "            return str(row)\n",
    "    \n",
    "    # create the udf object from the helper function\n",
    "    udf_object = F.udf(hashValues)\n",
    "    \n",
    "    # hash all hex strings in both train and test\n",
    "    for c in trainDf.columns[14:]:\n",
    "        trainDf = trainDf.withColumn(c, udf_object(trainDf[c]))\n",
    "        testDf = testDf.withColumn(c, udf_object(testDf[c]))\n",
    "        \n",
    "    # index the hash values into categories\n",
    "    for c in trainDf.columns[14:]:\n",
    "        newCol = c + '_idx'\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=newCol, handleInvalid='keep')\n",
    "        f = indexer.fit(trainDf)\n",
    "        trainDf = f.transform(trainDf)\n",
    "        testDf = f.transform(testDf)\n",
    "        \n",
    "    # One-hot encode the categorical indices\n",
    "    inputCols = trainDf.columns[40:]\n",
    "    outputCols = [c.strip('_idx') + '_OHE' for c in inputCols]\n",
    "    encoder = OneHotEncoderEstimator(inputCols=inputCols, outputCols=outputCols)\n",
    "    e = encoder.fit(trainDf)\n",
    "    trainDf = e.transform(trainDf)\n",
    "    testDf = e.transform(testDf)\n",
    "    \n",
    "    # assemble all features into single SparseVector column\n",
    "    cols = [c for c in trainDf.columns if 'n' in c or 'OHE' in c]\n",
    "    v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "    trainDf = v.transform(trainDf)\n",
    "    testDf = v.transform(testDf)\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sample\n",
    "trainSample, testSample = createFeatureVector(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('features', 'features')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.columns[-1], testSample.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(24135, {1: 0.0002, 13: 1.0, 448: 1.0, 1975: 1.0, 2180: 1.0, 3940: 1.0, 4686: 1.0, 5136: 1.0, 7158: 1.0, 7531: 1.0, 8424: 1.0, 9516: 1.0, 9713: 1.0, 11893: 1.0, 12462: 1.0, 14541: 1.0, 14548: 1.0, 14558: 1.0, 14580: 1.0, 15411: 1.0, 17808: 1.0, 18259: 1.0, 18598: 1.0, 18929: 1.0, 20167: 1.0, 21945: 1.0, 22148: 1.0}))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(24135, {1: 0.0002, 13: 1.0, 711: 1.0, 1975: 1.0, 4687: 1.0, 4694: 1.0, 7158: 1.0, 7675: 1.0, 8424: 1.0, 9516: 1.0, 9523: 1.0, 11893: 1.0, 11929: 1.0, 14542: 1.0, 14544: 1.0, 14557: 1.0, 14580: 1.0, 14909: 1.0, 17753: 1.0, 18259: 1.0, 18610: 1.0, 18714: 1.0, 20167: 1.0, 21945: 1.0, 22017: 1.0}))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSample.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample.write.format('parquet').save('data/trainSample.parquet')\n",
    "testSample.write.format('parquet').save('data/testSample.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 s, sys: 470 ms, total: 1.81 s\n",
      "Wall time: 9min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# on full\n",
    "train, test = createFeatureVector(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(109465, {1: 0.0, 13: 1.0, 92: 1.0, 7000: 1.0, 7117: 1.0, 12260: 1.0, 18098: 1.0, 21277: 1.0, 28116: 1.0, 28503: 1.0, 31171: 1.0, 41156: 1.0, 47668: 1.0, 51174: 1.0, 58617: 1.0, 61259: 1.0, 61265: 1.0, 61277: 1.0, 61548: 1.0, 66279: 1.0, 72302: 1.0, 75696: 1.0, 77570: 1.0, 78910: 1.0, 88906: 1.0, 98860: 1.0, 102345: 1.0}))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.write.format('parquet').save('data/trainPreProcessed.parquet')\n",
    "# test.write.format('parquet').save('data/devPreProcessed.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashCategoricals(trainDf, testDf):\n",
    "    # create hash function for binning categorical variables\n",
    "    def hashValues(row):\n",
    "        if row != None:\n",
    "            # return integer value of hex label, modulo by 10000 (keep only the last 4 digits)\n",
    "            return str(int('0x' + row, 16) % 10000)\n",
    "        else:\n",
    "            return str(row)\n",
    "    \n",
    "    # create the udf object from the helper function\n",
    "    udf_object = F.udf(hashValues)\n",
    "    \n",
    "    # hash all hex strings in both train and test\n",
    "    for c in trainDf.columns[14:]:\n",
    "        trainDf = trainDf.withColumn(c, udf_object(trainDf[c]))\n",
    "        testDf = testDf.withColumn(c, udf_object(testDf[c]))\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample, testSample = hashCategoricals(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0002068680182043856, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='8852', c1='8017', c2='4310', c3='8313', c4='4343', c5='2821', c6='3090', c7='84', c8='8418', c9='8539', c10='2816', c11='6109', c12='1890', c13='6422', c14='4146', c15='4642', c16='2577', c17='8733', c18='None', c19='None', c20='5227', c21='9419', c22='5356', c23='1146', c24='None', c25='None')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0002068680182043856, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='5684', c1='8017', c2='9656', c3='9545', c4='9704', c5='8079', c6='3090', c7='84', c8='8418', c9='8539', c10='2816', c11='1488', c12='1890', c13='2527', c14='5555', c15='7942', c16='2577', c17='7231', c18='None', c19='None', c20='1497', c21='None', c22='3739', c23='1592', c24='None', c25='None')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline implementation\n",
    "def createFeatureVector2(trainDf, testDf):\n",
    "    # generate stages for pipeline\n",
    "    stages = []\n",
    "    \n",
    "    # create indexer to hash values into categories\n",
    "    for c in trainDf.columns[14:]:\n",
    "        strIdxCol = c + '_idx'\n",
    "        oheCol = strIdxCol.strip('_idx') + '_OHE'\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=strIdxCol, handleInvalid='keep')\n",
    "        OHE = OneHotEncoderEstimator(inputCols=strIdxCol, outputCols=oheCol, dropLast=False)\n",
    "        stages += [indexer, OHE]\n",
    "        \n",
    "    # One-hot encode the categorical indices\n",
    "#     inputCols = trainDf.columns[40:]\n",
    "#     outputCols = [c.strip('_idx') + '_OHE' for c in inputCols]\n",
    "#     encoder = OneHotEncoderEstimator(inputCols=inputCols, outputCols=outputCols, dropLast=False)\n",
    "#     stages += [encoder]\n",
    "#     print(stages)\n",
    "#     e = encoder.fit(trainDf)\n",
    "#     trainDf = e.transform(trainDf)\n",
    "#     testDf = e.transform(testDf)\n",
    "    \n",
    "    # assemble all features into single SparseVector column\n",
    "#     cols = [c for c in trainDf.columns if 'n' in c or 'OHE' in c]\n",
    "#     v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "#     stages += [v]\n",
    "#     trainDf = v.transform(trainDf)\n",
    "#     testDf = v.transform(testDf)\n",
    "    \n",
    "    pipe = Pipeline(stages=stages)\n",
    "    model = pipe.fit(trainDf)\n",
    "    trainDf = model.transform(trainDf)\n",
    "    testDf = model.transform(testDf)\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0002068680182043856, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='8852', c1='8017', c2='4310', c3='8313', c4='4343', c5='2821', c6='3090', c7='84', c8='8418', c9='8539', c10='2816', c11='6109', c12='1890', c13='6422', c14='4146', c15='4642', c16='2577', c17='8733', c18='None', c19='None', c20='5227', c21='9419', c22='5356', c23='1146', c24='None', c25='None')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, tester = createFeatureVector2(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('features', 'features')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.columns[-1], tester.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0002068680182043856, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='8852', c1='8017', c2='4310', c3='8313', c4='4343', c5='2821', c6='3090', c7='84', c8='8418', c9='8539', c10='2816', c11='6109', c12='1890', c13='6422', c14='4146', c15='4642', c16='2577', c17='8733', c18='None', c19='None', c20='5227', c21='9419', c22='5356', c23='1146', c24='None', c25='None', c0_idx=1.0, c1_idx=0.0, c2_idx=2385.0, c3_idx=1150.0, c4_idx=6.0, c5_idx=2.0, c6_idx=68.0, c7_idx=0.0, c8_idx=1.0, c9_idx=0.0, c10_idx=97.0, c11_idx=231.0, c12_idx=12.0, c13_idx=0.0, c14_idx=969.0, c15_idx=1788.0, c16_idx=8.0, c17_idx=811.0, c18_idx=0.0, c19_idx=0.0, c20_idx=2235.0, c21_idx=1.0, c22_idx=3.0, c23_idx=361.0, c24_idx=0.0, c25_idx=0.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, n0=0.0, n1=0.0002068680182043856, n2=0.0, n3=0.0, n4=0.0, n5=0.0, n6=0.0, n7=0.0, n8=0.0, n9=0.0, n10=0.0, n11=0.0, n12=0.0, c0='5684', c1='8017', c2='9656', c3='9545', c4='9704', c5='8079', c6='3090', c7='84', c8='8418', c9='8539', c10='2816', c11='1488', c12='1890', c13='2527', c14='5555', c15='7942', c16='2577', c17='7231', c18='None', c19='None', c20='1497', c21='None', c22='3739', c23='1592', c24='None', c25='None', c0_idx=0.0, c1_idx=0.0, c2_idx=140.0, c3_idx=7.0, c4_idx=0.0, c5_idx=0.0, c6_idx=68.0, c7_idx=0.0, c8_idx=1.0, c9_idx=0.0, c10_idx=97.0, c11_idx=120.0, c12_idx=12.0, c13_idx=1.0, c14_idx=149.0, c15_idx=7.0, c16_idx=8.0, c17_idx=43.0, c18_idx=0.0, c19_idx=0.0, c20_idx=7.0, c21_idx=0.0, c22_idx=1.0, c23_idx=1.0, c24_idx=0.0, c25_idx=0.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample.write.format('parquet').save('data/trainSample.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
