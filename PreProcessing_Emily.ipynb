{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types, Row, Column\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"finalProject\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in raw text set and write to parquet\n",
    "#train = spark.read.option('header', 'false').csv('data/train.txt', sep='\\t')\n",
    "#train.write.format('parquet').save('data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODULO_NUMBER = 100000\n",
    "MODULO_NUMBER = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in parqet\n",
    "train = spark.read.parquet('gs://w261_desa2/notebooks/data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename label column\n",
    "train = train.withColumnRenamed('_c0', 'label')\n",
    "\n",
    "# remove underscores\n",
    "for c in train.columns[1:]:\n",
    "    train = train.withColumnRenamed(c, c.strip('_'))\n",
    "\n",
    "for i,c in enumerate(train.columns[1:14]):\n",
    "    newName = 'n' + str(i)\n",
    "    train = train.withColumnRenamed(c, newName)\n",
    "    \n",
    "for i,c in enumerate(train.columns[14:]):\n",
    "    newName = 'c' + str(i)\n",
    "    train = train.withColumnRenamed(c, newName)\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical is float\n",
    "for c in train.columns[:14]:\n",
    "    train = train.withColumn(c, train[c].cast('float'))\n",
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a sample\n",
    "train = train.sample(False, 0.01)\n",
    "#s = train\n",
    "#s.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sample\n",
    "#trainSample, testSample = s.randomSplit([9.0, 1.0], 666)\n",
    "#trainSample = trainSample.cache()\n",
    "#testSample = testSample.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainSample.count(), testSample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on full\n",
    "train, test = train.randomSplit([9.0, 1.0], 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.cache()\n",
    "test = test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count(), test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Section Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main feature engineering challenge with this dataset is how to reduce the number of features from the number that would result if we naively one-hot encoded each categorical variable. We experimented with two distinct solutions to this problem:\n",
    "- Modulo-based hashing function: We drew inspiration from the writeup of one of the kaggle competition winners, who used a hashing function to reduce the number of categorial variables. For this implementation, we kept all 26 of the initial categorical features, but dropped the infrequent values (any that occurred fewer than 10 times) and then took the variables that still had very large numbers of categories remaining and hashed them to a smaller size (effectively randomly binning multiple values for that feature into a single dummy feature). This methodology is explained in more detail below.\n",
    "- Random forest feature selection: Our desire to experiment with interaction terms in our model led us to the need to reduce our features much more significantly. We decided to try using feature importances from a Random Forest model in order to completely eliminate some of the categorical variables from the final training set. This also gave us a good excuse to learn how to use another model in the Spark ML package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Feature Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I feel like maybe this code for training the RF should go in an appendix or something, and in the main notebook, we should just show the code for loading in the trained RF, getting the features, and then including them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector assembler won't work if any values are null\n",
    "train = train.na.fill(0, subset=train.columns[1:14])\n",
    "test = test.na.fill(0, subset=test.columns[1:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [c for c in train.columns if 'c' in c or 'label' in c]\n",
    "indexed_cols = []\n",
    "for col in categorical_cols:\n",
    "    new_col_name = \"{}_indexed\".format(col)\n",
    "    vec_indexer = StringIndexer(inputCol=col, outputCol=new_col_name, handleInvalid='keep').fit(train)\n",
    "    train = vec_indexer.transform(train)\n",
    "    test = vec_indexer.transform(test)\n",
    "    indexed_cols.append(new_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_features = [c for c in train.columns if 'n' in c and c!=\"label_indexed\"]\n",
    "print(cols_for_features)\n",
    "assembler = VectorAssembler(inputCols=cols_for_features, outputCol=\"features\")\n",
    "newTrain = assembler.transform(train)\n",
    "newTest = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(labelCol=\"label_indexed\", featuresCol=\"features\", numTrees=5, maxBins=1300000)\n",
    "fit_rf = rf.fit(newTrain)\n",
    "end_time = time.time()\n",
    "print(\"Total time taken = {}\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fit_rf.transform(newTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### probably need to write a function to get accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.filter(predictions[\"prediction\"]==1).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rf.save('gs://w261_desa2/notebooks/models/emBaselineRf1PercentSample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rf.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While normalizing the numeric data isn't strictly necessary for logistic regression, it is helpful to have features be generally in the same scale when using gradient descent, as it prevents the cost function from being significantly steeper around certain parameters due to scale only (can someone explain this better than I can??). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeNumeric(trainDf, testDf):\n",
    "    stats = trainDf[trainDf.columns[1:14]].describe()\n",
    "    maxes = np.array(stats[stats['summary'] == 'max'].collect())[0][1:]\n",
    "    mins = np.array(stats[stats['summary'] == 'min'].collect())[0][1:]\n",
    "    maxes = [float(m) for m in maxes]\n",
    "    mins = [float(m) for m in mins]\n",
    "    \n",
    "    for i,c in enumerate(trainDf.columns[1:14]):\n",
    "        trainDf = trainDf.withColumn(c, (trainDf[c] - mins[i]) / (maxes[i] - mins[i]))\n",
    "        testDf = testDf.withColumn(c, (testDf[c] - mins[i]) / (maxes[i] - mins[i]))\n",
    "        \n",
    "    trainDf = trainDf.na.fill(0, subset=trainDf.columns[1:14])\n",
    "    testDf = testDf.na.fill(0, subset=testDf.columns[1:14])\n",
    "    \n",
    "    return trainDf, testDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sample\n",
    "#trainSample, testSample = normalizeNumeric(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testSample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = normalizeNumeric(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatureVector(trainDf, testDf, n=10, modulo=10000):\n",
    "    \n",
    "    \n",
    "    def findInfrequentValues(c, n=10):\n",
    "        # c is the column that we are operating on\n",
    "        counts = trainDf.groupBy(c).count()\n",
    "        infrequentValues = counts.filter(counts['count'] <= n)\n",
    "        s = infrequentValues.agg(F.collect_set(c)).collect()[0][0]\n",
    "        return s\n",
    "\n",
    "    # this value infreq_values is GLOBAL, rather than a param passed into the function\n",
    "    # i really don't love that, but I can't figure out how to do it otherwise\n",
    "    def replaceInfrequentValues(row_value):\n",
    "        if row_value in infreq_values:\n",
    "            return \"infreq\"\n",
    "        else:\n",
    "            return row_value\n",
    "\n",
    "    #def replaceInfreqWrapper(infreq_list):\n",
    "    #    return F.udf(lambda l: replaceInfrequentValues(l, infreq_list))\n",
    "\n",
    "    #replaceInfreqWrapper=F.udf(lambda x: replaceInfrequentValues(x, infreq_values), types.StringType())\n",
    "\n",
    "    replace_infreq_udf = F.udf(replaceInfrequentValues)\n",
    "\n",
    "    # create hash function for binning categorical variables\n",
    "    def hashValues(row):\n",
    "        if row == \"infreq\":\n",
    "            return str(row)\n",
    "        elif row != None:\n",
    "            # return integer value of hex label, modulo by 10000 (keep only the last 4 digits)\n",
    "            return str(int('0x' + row, 16) % 10000)\n",
    "        else:\n",
    "            return str(row)\n",
    "\n",
    "    # create the udf object from the helper function\n",
    "    hash_udf = F.udf(hashValues)\n",
    "\n",
    "    # hash all hex strings in both trainDfand test\n",
    "    for c in trainDf.columns[14:]:\n",
    "        print(\"eliminating infreqs/hashing column {}\".format(c))\n",
    "        infreq_values = findInfrequentValues(trainDf[c])\n",
    "        trainDf = trainDf.withColumn(c, replace_infreq_udf(trainDf[c]))\n",
    "        testDf = testDf.withColumn(c, replace_infreq_udf(testDf[c]))\n",
    "        unique_values = trainDf.agg(F.countDistinct(trainDf[c])).collect()[0][0]\n",
    "        if unique_values > 10000:\n",
    "            trainDf = trainDf.withColumn(c, hash_udf(trainDf[c]))\n",
    "            testDf = testDf.withColumn(c, hash_udf(testDf[c]))\n",
    "  \n",
    "    # index the hash values into categories\n",
    "    for c in trainDf.columns[14:]:\n",
    "        newCol = c + '_idx'\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=newCol, handleInvalid='keep')\n",
    "        f = indexer.fit(trainDf)\n",
    "        trainDf = f.transform(trainDf)\n",
    "        testDf = f.transform(testDf)\n",
    "        \n",
    "    # One-hot encode the categorical indices\n",
    "    inputCols = trainDf.columns[40:]\n",
    "    outputCols = [c.strip('_idx') + '_OHE' for c in inputCols]\n",
    "    encoder = OneHotEncoderEstimator(inputCols=inputCols, outputCols=outputCols)\n",
    "    e = encoder.fit(trainDf)\n",
    "    trainDf = e.transform(trainDf)\n",
    "    testDf = e.transform(testDf)\n",
    "\n",
    "    # assemble all features into single SparseVector column\n",
    "    cols = [c for c in trainDf.columns if 'n' in c or 'OHE' in c]\n",
    "    v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "    trainDf = v.transform(trainDf)\n",
    "    testDf = v.transform(testDf)\n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, test = createFeatureVector(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.select('features').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.write.format('parquet').save('gs:/notebooks/data/e412fullTrainMod50k.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.write.format('parquet').save('gs:/notebooks/data/e412fullTestMod50k.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to get something to run as a proof of concept, then we can iterate longer later\n",
    "# default value is 100\n",
    "MAXITER = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='label', \n",
    "    regParam=0.01, \n",
    "    family='binomial',\n",
    "    standardization=False,\n",
    "    maxIter=MAXITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = model.summary\n",
    "history = trainingSummary.objectiveHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSummary = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSummary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gs://w261_desa2/notebooks/models/baselineModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameModel = LogisticRegressionModel.load('gs://w261_desa2/notebooks/models/baselineModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashCategoricals(trainDf, testDf):\n",
    "    # create hash function for binning categorical variables\n",
    "    def hashValues(row):\n",
    "        if row != None:\n",
    "            # return integer value of hex label, modulo by 10000 (keep only the last 4 digits)\n",
    "            return str(int('0x' + row, 16) % 10000)\n",
    "        else:\n",
    "            return str(row)\n",
    "    \n",
    "    # create the udf object from the helper function\n",
    "    udf_object = F.udf(hashValues)\n",
    "    \n",
    "    # hash all hex strings in both train and test\n",
    "    for c in trainDf.columns[14:]:\n",
    "        trainDf = trainDf.withColumn(c, udf_object(trainDf[c]))\n",
    "        testDf = testDf.withColumn(c, udf_object(testDf[c]))\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample, testSample = hashCategoricals(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline implementation\n",
    "def createFeatureVector2(trainDf, testDf):\n",
    "    # generate stages for pipeline\n",
    "    stages = []\n",
    "    \n",
    "    # create indexer to hash values into categories\n",
    "    for c in trainDf.columns[14:]:\n",
    "        strIdxCol = c + '_idx'\n",
    "        oheCol = strIdxCol.strip('_idx') + '_OHE'\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=strIdxCol, handleInvalid='keep')\n",
    "        OHE = OneHotEncoderEstimator(inputCols=strIdxCol, outputCols=oheCol, dropLast=False)\n",
    "        stages += [indexer, OHE]\n",
    "        \n",
    "    # One-hot encode the categorical indices\n",
    "#     inputCols = trainDf.columns[40:]\n",
    "#     outputCols = [c.strip('_idx') + '_OHE' for c in inputCols]\n",
    "#     encoder = OneHotEncoderEstimator(inputCols=inputCols, outputCols=outputCols, dropLast=False)\n",
    "#     stages += [encoder]\n",
    "#     print(stages)\n",
    "#     e = encoder.fit(trainDf)\n",
    "#     trainDf = e.transform(trainDf)\n",
    "#     testDf = e.transform(testDf)\n",
    "    \n",
    "    # assemble all features into single SparseVector column\n",
    "#     cols = [c for c in trainDf.columns if 'n' in c or 'OHE' in c]\n",
    "#     v = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "#     stages += [v]\n",
    "#     trainDf = v.transform(trainDf)\n",
    "#     testDf = v.transform(testDf)\n",
    "    \n",
    "    pipe = Pipeline(stages=stages)\n",
    "    model = pipe.fit(trainDf)\n",
    "    trainDf = model.transform(trainDf)\n",
    "    testDf = model.transform(testDf)\n",
    "    \n",
    "    return trainDf.cache(), testDf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, tester = createFeatureVector2(trainSample, testSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.columns[-1], tester.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample.write.format('parquet').save('data/trainSample.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}